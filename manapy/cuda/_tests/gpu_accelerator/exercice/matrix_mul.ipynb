{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "#init\n",
    "M = 1024\n",
    "K = 1024\n",
    "N = 1024\n",
    "a = np.arange(M * K).reshape(M, K).astype(np.float64)\n",
    "b = np.ones(K * N).reshape(K, N).astype(np.float64)\n",
    "c = np.zeros(M * N).reshape(M, N).astype(np.float64)\n",
    "\n",
    "\n",
    "#cuda allocation\n",
    "d_a = cuda.to_device(a)\n",
    "d_b = cuda.to_device(b)\n",
    "d_c = cuda.to_device(c)\n",
    "#d_c = cuda.device_array((dim, dim), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.24 ms ± 17.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit c = a @ b #1024 1024 1024 -> 17.2microsec, -> int 9.11ms !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify result\n",
    "\n",
    "def verify(a, b, c):\n",
    "  cpu_res = np.dot(a, b)\n",
    "  np.testing.assert_almost_equal(c, cpu_res, decimal=2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matrix_mul(a, b, c, M, K, N):\n",
    "  i, j = cuda.grid(2)\n",
    "  if i < M and j < N:\n",
    "    c[i][j] = 0.0\n",
    "    for k in range(K):\n",
    "      c[i][j] += a[i][k] * b[k][j]\n",
    "\n",
    "threads_per_block = (32, 32)\n",
    "blocks = (32, 32)\n",
    "matrix_mul[blocks, threads_per_block](d_a, d_b, d_c, M, K, N)\n",
    "host_c = d_c.copy_to_host()\n",
    "host_c\n",
    "\n",
    "verify(a, b, host_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.2 ms ± 66.4 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit matrix_mul[blocks, threads_per_block](d_a, d_b, d_c, M, K, N); cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.7 ms ± 6.42 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "#changing i, j to be j, i for Coalesced Access\n",
    "#using tmp as a local variable\n",
    "#to improve performance\n",
    "\n",
    "@cuda.jit\n",
    "def matrix_mul(a, b, c, M, K, N):\n",
    "  j, i = cuda.grid(2)\n",
    "  if i < M and j < N:\n",
    "    tmp = 0.0\n",
    "    for k in range(K):\n",
    "      tmp += a[i][k] * b[k][j]\n",
    "    c[i][j] = tmp\n",
    "\n",
    "threads_per_block = (32, 32)\n",
    "blocks = (32, 32)\n",
    "%timeit matrix_mul[blocks, threads_per_block](d_a, d_b, d_c, M, K, N); cuda.synchronize()\n",
    "host_c = d_c.copy_to_host()\n",
    "verify(a, b, host_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.2 ms ± 196 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "#stride for large matrix up to dim = 32 * 32 * 32 * 32 * 32 * 32\n",
    "@cuda.jit\n",
    "def matrix_mul(a, b, c, M, K, N):\n",
    "  y, x = cuda.grid(2)\n",
    "  strideX, strideY = cuda.gridsize(2)\n",
    "\n",
    "  for i in range(x, M, strideX):\n",
    "    for j in range(y, N, strideY):\n",
    "      tmp = 0.0\n",
    "      for k in range(K):\n",
    "        tmp += a[i][k] * b[k][j]\n",
    "      c[i][j] = tmp\n",
    "\n",
    "threads_per_block = (32, 32)\n",
    "blocks = (32, 32)\n",
    "%timeit matrix_mul[blocks, threads_per_block](d_a, d_b, d_c, M, K, N); cuda.synchronize()\n",
    "host_c = d_c.copy_to_host()\n",
    "verify(a, b, host_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.4 ms ± 61.6 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda, float32\n",
    "\n",
    "TPB = 32\n",
    "\n",
    "@cuda.jit\n",
    "def matrix_mul(A, B, C, dim):\n",
    "  col, row = cuda.grid(2)\n",
    "  x = cuda.threadIdx.x\n",
    "  y = cuda.threadIdx.y\n",
    "  \n",
    "  sa = cuda.shared.array(shape=(32, 32), dtype=float32)\n",
    "  sb = cuda.shared.array(shape=(32, 32), dtype=float32)\n",
    "  \n",
    "  tmp = 0.0\n",
    "  for tile in range(0, cuda.gridDim.x):\n",
    "    j = tile * 32 + x\n",
    "    i = tile * 32 + y\n",
    "\n",
    "    # Coalesced access\n",
    "    sa[y][x] = A[row][j]\n",
    "    sb[y][x] = B[i][col]\n",
    "\n",
    "    cuda.syncthreads()\n",
    "\n",
    "    for k in range(0, 32):\n",
    "      tmp += sa[y][k] * sb[k][x] #no bank conflicts\n",
    "\n",
    "    cuda.syncthreads()\n",
    "  \n",
    "  C[row][col] = tmp\n",
    "\n",
    "threads_per_block = (TPB, TPB)\n",
    "blocks = (32, 32)\n",
    "%timeit matrix_mul[blocks, threads_per_block](d_a, d_b, d_c, 2048); cuda.synchronize()\n",
    "host_c = d_c.copy_to_host()\n",
    "#verify(a, b, host_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "CudaAPIError",
     "evalue": "[700] Call to cuCtxSynchronize results in UNKNOWN_CUDA_ERROR",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCudaAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m threads_per_block \u001b[38;5;241m=\u001b[39m (TPB, TPB)\n\u001b[1;32m     40\u001b[0m blocks \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatrix_mul[blocks, threads_per_block](d_a, d_b, d_c, 2048); cuda.synchronize()\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m host_c \u001b[38;5;241m=\u001b[39m d_c\u001b[38;5;241m.\u001b[39mcopy_to_host()\n\u001b[1;32m     43\u001b[0m verify(a, b, host_c)\n",
      "File \u001b[0;32m~/.conda/envs/stage/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2417\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2415\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2416\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2417\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2419\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2420\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2421\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.conda/envs/stage/lib/python3.8/site-packages/IPython/core/magics/execution.py:1170\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m   1169\u001b[0m     number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m index\n\u001b[0;32m-> 1170\u001b[0m     time_number \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[1;32m   1172\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/stage/lib/python3.8/site-packages/IPython/core/magics/execution.py:158\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    156\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:1\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/stage/lib/python3.8/site-packages/numba/cuda/api.py:244\u001b[0m, in \u001b[0;36msynchronize\u001b[0;34m()\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msynchronize\u001b[39m():\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSynchronize the current context.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcurrent_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/stage/lib/python3.8/site-packages/numba/cuda/cudadrv/driver.py:1499\u001b[0m, in \u001b[0;36mContext.synchronize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msynchronize\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1499\u001b[0m     \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuCtxSynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/stage/lib/python3.8/site-packages/numba/cuda/cudadrv/driver.py:320\u001b[0m, in \u001b[0;36mDriver._ctypes_wrap_fn.<locals>.safe_cuda_api_call\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    318\u001b[0m _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall driver api: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, libfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    319\u001b[0m retcode \u001b[38;5;241m=\u001b[39m libfn(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_ctypes_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretcode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/stage/lib/python3.8/site-packages/numba/cuda/cudadrv/driver.py:388\u001b[0m, in \u001b[0;36mDriver._check_ctypes_error\u001b[0;34m(self, fname, retcode)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retcode \u001b[38;5;241m==\u001b[39m enums\u001b[38;5;241m.\u001b[39mCUDA_ERROR_NOT_INITIALIZED:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_fork()\n\u001b[0;32m--> 388\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m CudaAPIError(retcode, msg)\n",
      "\u001b[0;31mCudaAPIError\u001b[0m: [700] Call to cuCtxSynchronize results in UNKNOWN_CUDA_ERROR"
     ]
    }
   ],
   "source": [
    "from numba import cuda, float32\n",
    "\n",
    "TPB = 32\n",
    "\n",
    "@cuda.jit\n",
    "def matrix_mul(A, B, C, dim):\n",
    "  thx, thy = cuda.grid(2)\n",
    "  strideX, strideY = cuda.gridsize(2)\n",
    "\n",
    "  sa = cuda.shared.array(shape=(32, 32), dtype=float32)\n",
    "  sb = cuda.shared.array(shape=(32, 32), dtype=float32)\n",
    "\n",
    "  for col in range(thx, dim, strideX):\n",
    "    for row in range(thy, dim, strideY):\n",
    "      #col, row = cuda.grid(2)\n",
    "      \n",
    "      x = cuda.threadIdx.x\n",
    "      y = cuda.threadIdx.y\n",
    "      \n",
    "      tmp = 0.0\n",
    "      \n",
    "      for tile in range(0, cuda.gridDim.x * 2):\n",
    "        j = tile * 32 + x\n",
    "        i = tile * 32 + y\n",
    "\n",
    "        # Coalesced access\n",
    "        sa[y][x] = A[row][j]\n",
    "        sb[y][x] = B[i][col]\n",
    "\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        for k in range(0, 32):\n",
    "          tmp += sa[y][k] * sb[k][x] #no bank conflicts\n",
    "\n",
    "        cuda.syncthreads()\n",
    "      \n",
    "      C[row][col] = tmp\n",
    "\n",
    "threads_per_block = (TPB, TPB)\n",
    "blocks = (32, 32)\n",
    "%timeit matrix_mul[blocks, threads_per_block](d_a, d_b, d_c, 2048); cuda.synchronize()\n",
    "host_c = d_c.copy_to_host()\n",
    "verify(a, b, host_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!make attention for float32 precision because large number can accumulate error always make test using double precesion\n",
    "\n",
    "#some number of blocks per grid even if they are small like 64 result of UNKNOWENE CUDA ERROR,\n",
    "# if that happen the execution of the next kernel will fail even if the kernel is valid\n",
    "\n",
    "#testing the matrix multiolication using shared memory in numba using GTX950M of my laptop result of slitly slow compared of\n",
    "# the just using local variable, but using c/c++ cuda programming language the result was very fast (x7.5) from 100ms to 13ms\n",
    "# the reason i don't know\n",
    "\n",
    "# using stride of 32 in matrix multiplication is conveinte because it can traite matrix of large number up to 1 billion \n",
    "  # 32 * 32 * 32 * 32 * 32 *32 and the memory of the gpu is limited it is of the order gibyte\n",
    "\n",
    "# there is some advance teqnics to get even fast kernel but i need more time to invastagate them \n",
    "  # https://github.com/siboehm/SGEMM_CUDA/tree/master\n",
    "\n",
    "# using pytorch a python libarary for training ai models the matrix multiplication is so fast using gpu 2ms\n",
    "\n",
    "# in numpy matrix multiplication using int32 is to slow compared to using float32 (1s vs 9ms)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-stage] *",
   "language": "python",
   "name": "conda-env-.conda-stage-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
